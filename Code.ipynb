{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44514500-1c48-4302-b5c9-d6e289b44a29",
   "metadata": {},
   "source": [
    "# Assignment: Structuring Data for Effective Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "#### Objective:\n",
    "Your task is to develop a unique data/embedding structure that organizes the information from the provided GStreamer tutorial in a way that enhances the performance of a Retrieval-Augmented Generation (RAG) model. The goal is to ensure that the data is well-linked and easily understandable, allowing the RAG model to fetch and utilize the most important information efficiently.\n",
    "\n",
    "#### Resources:\n",
    "•⁠  ⁠*Text Source*: [GStreamer Tutorial - Dynamic Pipelines](https://gstreamer.freedesktop.org/documentation/tutorials/basic/dynamic-pipelines.html?gi-language=c)\n",
    "\n",
    "#### Instructions:\n",
    "1.⁠ ⁠*Understand the Content*:\n",
    "   - Thoroughly read and understand the provided GStreamer tutorial.\n",
    "   - Identify key sections, concepts, and terminologies.\n",
    "\n",
    "2.⁠ ⁠*Data Structuring*:\n",
    "   - Break down the content into logical sections such as Introduction, Concepts, Examples, and Code Snippets.\n",
    "   - Create a hierarchical structure that reflects the flow of the tutorial, linking related sections and sub-sections.\n",
    "\n",
    "3.⁠ ⁠*Embedding Strategy (Optional)*:\n",
    "   - Design an embedding strategy that captures the essence of each section.\n",
    "   - Ensure that embeddings for similar or related sections are closely linked, facilitating easy navigation and retrieval.\n",
    "\n",
    "4.⁠ ⁠*Linking Data*:\n",
    "   - Develop a system for linking related pieces of information. For example, code snippets should be linked to the explanations and concepts they demonstrate.\n",
    "   - Use metadata to tag sections with relevant keywords and concepts for better indexing and retrieval.\n",
    "\n",
    "#### Deliverables:\n",
    "•⁠  ⁠A structured document/file containing the organized data from the GStreamer tutorial.\n",
    "•⁠  ⁠A written explanation of your data structure and embedding strategy.\n",
    "•⁠  ⁠(Optional) Results and feedback from testing with a RAG model.\n",
    "\n",
    "---\n",
    "\n",
    "If you have any questions or need further clarification, feel free to reach out .\n",
    "\n",
    "Good luck and happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d251b824-79ac-43b6-838f-36ae77718a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content scraped and saved to 'Vishwas.txt'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the GStreamer Tutorial\n",
    "url = \"https://gstreamer.freedesktop.org/documentation/tutorials/basic/dynamic-pipelines.html?gi-language=c\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract relevant sections\n",
    "title = soup.find(\"h1\").get_text()\n",
    "content = \"\"\n",
    "\n",
    "# Collect all the paragraphs and headings\n",
    "for element in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"p\", \"pre\"]):\n",
    "    content += element.get_text() + \"\\n\\n\"\n",
    "\n",
    "# Save the content to a file\n",
    "with open(\"Vishwas.txt\", \"w\") as file:\n",
    "    file.write(content)\n",
    "\n",
    "print(\"Content scraped and saved to 'Vishwas.txt'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b3f30be-6aae-4d4d-95c3-0a41786458e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"GStreamerTutorial\": {\n",
      "    \"metadata\": {\n",
      "      \"keywords\": [\n",
      "        \"GStreamer\",\n",
      "        \"dynamic pipelines\",\n",
      "        \"tutorial\",\n",
      "        \"coding\",\n",
      "        \"multimedia\"\n",
      "      ],\n",
      "      \"links\": [\n",
      "        \"https://gstreamer.freedesktop.org/documentation/tutorials/basic/dynamic-pipelines.html\"\n",
      "      ]\n",
      "    },\n",
      "    \"Introduction\": {\n",
      "      \"content\": \"This tutorial shows the rest of the basic concepts required to use GStreamer, which allow building the pipeline 'on the fly', as information becomes available, instead of having a monolithic pipeline defined at the beginning of your application. After this tutorial, you will have the necessary knowledge to start the Playback tutorials. The points reviewed here will be: How to attain finer control when linking elements. How to be notified of interesting events so you can react in time. The various states in which an element can be.\",\n",
      "      \"metadata\": {\n",
      "        \"keywords\": [\n",
      "          \"GStreamer\",\n",
      "          \"Introduction\",\n",
      "          \"dynamic pipelines\",\n",
      "          \"basic concepts\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"Concepts\": {\n",
      "      \"content\": \"The pipeline in this tutorial is not completely built before it is set to the playing state. This is OK. If we did not take further action, data would reach the end of the pipeline and the pipeline would produce an error message and stop. But we are going to take further action. In this example we are opening a file which is multiplexed (or muxed), this is, audio and video are stored together inside a container file. The elements responsible for opening such containers are called demuxers, and some examples of container formats are Matroska (MKV), Quick Time (QT, MOV), Ogg, or Advanced Systems Format (ASF, WMV, WMA).\",\n",
      "      \"metadata\": {\n",
      "        \"keywords\": [\n",
      "          \"GStreamer\",\n",
      "          \"Concepts\",\n",
      "          \"pipeline\",\n",
      "          \"multiplexed file\",\n",
      "          \"demuxers\",\n",
      "          \"container formats\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"Examples\": {\n",
      "      \"content\": \"For simplicity, in this example, we will only link to the audio pad and ignore the video. Copy this code into a text file named basic-tutorial-3.c (or find it in your GStreamer installation). If you need help to compile this code, refer to the Building the tutorials  section for your platform: Linux, Mac OS X or Windows, or use this specific command on Linux: gcc basic-tutorial-3.c -o basic-tutorial-3 `pkg-config --cflags --libs gstreamer-1.0` If you need help to run this code, refer to the Running the tutorials section for your platform: Linux, Mac OS X or Windows.\",\n",
      "      \"metadata\": {\n",
      "        \"keywords\": [\n",
      "          \"GStreamer\",\n",
      "          \"Examples\",\n",
      "          \"audio pad\",\n",
      "          \"video pad\",\n",
      "          \"compiling\",\n",
      "          \"running tutorial\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"CodeSnippets\": {\n",
      "      \"content\": \"#include <gst/gst.h> /* Structure to contain all our information, so we can pass it to callbacks */ typedef struct _CustomData {   GstElement *pipeline;   GstElement *source;   GstElement *convert;   GstElement *resample;   GstElement *sink; } CustomData; /* Handler for the pad-added signal */ static void pad_added_handler (GstElement *src, GstPad *pad, CustomData *data); int main(int argc, char *argv[]) {   CustomData data;   GstBus *bus;   GstMessage *msg;   GstStateChangeReturn ret;   gboolean terminate = FALSE; /* Initialize GStreamer */   gst_init (&argc, &argv); /* Create the elements */   data.source = gst_element_factory_make (\\\"uridecodebin\\\", \\\"source\\\");   data.convert = gst_element_factory_make (\\\"audioconvert\\\", \\\"convert\\\");   data.resample = gst_element_factory_make (\\\"audioresample\\\", \\\"resample\\\");   data.sink = gst_element_factory_make (\\\"autoaudiosink\\\", \\\"sink\\\"); /* Create the empty pipeline */   data.pipeline = gst_pipeline_new (\\\"test-pipeline\\\"); if (!data.pipeline || !data.source || !data.convert || !data.resample || !data.sink) {     g_printerr (\\\"Not all elements could be created.\\\\n\\\");     return -1;   } /* Build the pipeline. Note that we are NOT linking the source at this    * point. We will do it later. */   gst_bin_add_many (GST_BIN (data.pipeline), data.source, data.convert, data.resample, data.sink, NULL); if (!gst_element_link_many (data.convert, data.resample, data.sink, NULL)) {     g_printerr (\\\"Elements could not be linked.\\\\n\\\");     gst_object_unref (data.pipeline);     return -1;   } /* Set the URI to play */   g_object_set (data.source, \\\"uri\\\", \\\"https://gstreamer.freedesktop.org/data/media/sintel_trailer-480p.webm\\\", NULL); /* Connect to the pad-added signal */   g_signal_connect (data.source, \\\"pad-added\\\", G_CALLBACK (pad_added_handler), &data); /* Start playing */   ret = gst_element_set_state (data.pipeline, GST_STATE_PLAYING); if (ret == GST_STATE_CHANGE_FAILURE) {     g_printerr (\\\"Unable to set the pipeline to the playing state.\\\\n\\\");     gst_object_unref (data.pipeline);     return -1;   } /* Listen to the bus */   bus = gst_element_get_bus (data.pipeline); do {     msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE,         GST_MESSAGE_STATE_CHANGED | GST_MESSAGE_ERROR | GST_MESSAGE_EOS); /* Parse message */     if (msg != NULL) {       GError *err;       gchar *debug_info; switch (GST_MESSAGE_TYPE (msg)) {         case GST_MESSAGE_ERROR:           gst_message_parse_error (msg, &err, &debug_info);           g_printerr (\\\"Error received from element %s: %s\\\\n\\\", GST_OBJECT_NAME (msg->src), err->message);           g_printerr (\\\"Debugging information: %s\\\\n\\\", debug_info ? debug_info : \\\"none\\\");           g_clear_error (&err);           g_free (debug_info);           terminate = TRUE;           break;         case GST_MESSAGE_EOS:           g_print (\\\"End-Of-Stream reached.\\\\n\\\");           terminate = TRUE;           break;         case GST_MESSAGE_STATE_CHANGED:           /* We are only interested in state-changed messages from the pipeline */           if (GST_MESSAGE_SRC (msg) == GST_OBJECT (data.pipeline)) {             GstState old_state, new_state, pending_state;             gst_message_parse_state_changed (msg, &old_state, &new_state, &pending_state);             g_print (\\\"Pipeline state changed from %s to %s:\\\\n\\\",                 gst_element_state_get_name (old_state), gst_element_state_get_name (new_state));           }           break;         default:           /* We should not reach here */           g_printerr (\\\"Unexpected message received.\\\\n\\\");           break;       }       gst_message_unref (msg);     }   } while (!terminate); /* Free resources */   gst_object_unref (bus);   gst_element_set_state (data.pipeline, GST_STATE_NULL);   gst_object_unref (data.pipeline);   return 0; } /* This function will be called by the pad-added signal */ static void pad_added_handler (GstElement *src, GstPad *new_pad, CustomData *data) {   GstPad *sink_pad = gst_element_get_static_pad (data->convert, \\\"sink\\\");   GstPadLinkReturn ret;   GstCaps *new_pad_caps = NULL;   GstStructure *new_pad_struct = NULL;   const gchar *new_pad_type = NULL; g_print (\\\"Received new pad '%s' from '%s':\\\\n\\\", GST_PAD_NAME (new_pad), GST_ELEMENT_NAME (src)); /* If our converter is already linked, we have nothing to do here */   if (gst_pad_is_linked (sink_pad)) {     g_print (\\\"We are already linked. Ignoring.\\\\n\\\");     goto exit;   } /* Check the new pad's type */   new_pad_caps = gst_pad_get_current_caps (new_pad);   new_pad_struct = gst_caps_get_structure (new_pad_caps, 0);   new_pad_type = gst_structure_get_name (new_pad_struct); if (!g_str_has_prefix (new_pad_type, \\\"audio/x-raw\\\")) {     g_print (\\\"It has type '%s' which is not raw audio. Ignoring.\\\\n\\\", new_pad_type);     goto exit;   } /* Attempt the link */   ret = gst_pad_link (new_pad, sink_pad); if (GST_PAD_LINK_FAILED (ret)) {     g_print (\\\"Type is '%s' but link failed.\\\\n\\\", new_pad_type);   } else {     g_print (\\\"Link succeeded (type '%s').\\\\n\\\", new_pad_type);   } exit:   /* Unreference the new pad's caps, if we got them */   if (new_pad_caps != NULL)     gst_caps_unref (new_pad_caps); /* Unreference the sink pad */   gst_object_unref (sink_pad); }\",\n",
      "      \"metadata\": {\n",
      "        \"keywords\": [\n",
      "          \"GStreamer\",\n",
      "          \"CodeSnippets\",\n",
      "          \"C code\",\n",
      "          \"GstElement\",\n",
      "          \"pipeline\",\n",
      "          \"dynamic linking\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Formatted output has been saved to 'output.json'\n"
     ]
    }
   ],
   "source": [
    "# My openai key is saved in .env file\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to read content from file\n",
    "def read_content(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Read content from \"Vishwas.txt\"\n",
    "filename = \"Vishwas.txt\"\n",
    "content = read_content(filename)\n",
    "\n",
    "# Define the function schema for OpenAI function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"parse_gstreamer_tutorial\",\n",
    "        \"description\": \"Structure GStreamer tutorial into hierarchical JSON format\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"GStreamerTutorial\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"metadata\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "                                \"links\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                            }\n",
    "                        },\n",
    "                        \"Introduction\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"content\": {\"type\": \"string\"},\n",
    "                                \"metadata\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"Concepts\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"content\": {\"type\": \"string\"},\n",
    "                                \"metadata\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"Examples\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"content\": {\"type\": \"string\"},\n",
    "                                \"metadata\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"CodeSnippets\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"content\": {\"type\": \"string\"},\n",
    "                                \"metadata\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"metadata\", \"Introduction\", \"Concepts\", \"Examples\", \"CodeSnippets\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"GStreamerTutorial\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the prompt for OpenAI function call\n",
    "prompt = f\"\"\"\n",
    "    The following is the content of a GStreamer tutorial on dynamic pipelines. Please structure it into a hierarchical JSON format with sections such as Introduction, Concepts, Examples, and Code Snippets. Also, include metadata keywords and links to related sections.\n",
    "\n",
    "    Content:\n",
    "    {content}\n",
    "\n",
    "    Please structure the content into the format specified in the function schema, ensuring that each section has appropriate content and metadata.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Call OpenAI function to structure content\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        functions=functions,\n",
    "        function_call={\"name\": \"parse_gstreamer_tutorial\"},\n",
    "        max_tokens=2000,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    # Check for response errors or incomplete data\n",
    "    if response and response.choices and response.choices[0].message:\n",
    "        message = response.choices[0].message\n",
    "        if message.function_call:\n",
    "            structured_content = json.loads(message.function_call.arguments)\n",
    "            \n",
    "            # Pretty print the JSON with indentation\n",
    "            print(json.dumps(structured_content, indent=2))\n",
    "            \n",
    "            # Save the formatted output to a file\n",
    "            with open(\"organized_data_from_GS.json\", \"w\") as outfile:\n",
    "                json.dump(structured_content, outfile, indent=2)\n",
    "            print(\"\\nFormatted output has been saved to 'output.json'\")\n",
    "        else:\n",
    "            print(\"No function call in the response. Check API logs for more details.\")\n",
    "    else:\n",
    "        print(\"Response was empty or incomplete. Check API logs for more details.\")\n",
    "\n",
    "except json.JSONDecodeError as json_error:\n",
    "    print(f\"JSON Decoding Error: {json_error}\")\n",
    "    print(\"Raw response:\")\n",
    "    print(message.function_call.arguments)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49747c19-06a8-47d6-b1ca-44cc85c1dce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain the concept of dynamic pipelines in GStreamer.\n",
      "Response: Dynamic pipelines in GStreamer refer to the ability to build and modify media processing pipelines 'on the fly'. This means that as new information becomes available or circumstances change, you can add, remove, or modify elements within your pipeline during runtime. This provides a great deal of flexibility and enables complex use-cases compared to static pipelines where all elements and their configurations are pre-defined when the pipeline is created.\n",
      "\n",
      "One significant aspect of dynamic pipeline handling in GStreamer is \"Pad\" and \"Ghost Pad\". Pads act as input/output ports for elements and can be created or linked on demand. Ghost pad is a special type of pad to facilitate connection across bin boundaries, helping in encapsulating logic inside bins while dynamically linking elements.\n",
      "\n",
      "Another important factor is understanding the different states of the elements and the pipelines. GStreamer pipelines have four different states - NULL, READY, PAUSED, and PLAYING. The transition between these states allows you to manage the system resources effectively and control the data flow between the elements. \n",
      "\n",
      "However, working with dynamic pipelines requires correct handling of buffering, timestamps, event synchronization, and state changes. Understanding how to deal with these challenges is also crucial for successful implementation. \n",
      "\n",
      "Monitoring or reacting to events is another vital part of GStreamer dynamic pipelines. Events like EOS (end-of-stream), errors, metadata updates, etc., can trigger actions in your application. You can listen to these events by connecting callback functions to the \"message\" signal emitted by the pipeline bus. \n",
      "\n",
      "To conclude, dynamic pipelines offer a strong feature in GStreamer to build efficient, flexible, and complex multimedia applications. However, managing dynamic pipelines requires an understanding of various concepts like pad linking, states, event handling, etc.\n",
      "Results have been saved to 'result.txt'\n",
      "Embeddings have been saved to 'embeddings.json'\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "# Step 2: Implement embedding strategy\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def create_embeddings(structured_content):\n",
    "    embeddings = {}\n",
    "    for section, content in structured_content['GStreamerTutorial'].items():\n",
    "        if section != 'metadata':\n",
    "            section_text = content['content']\n",
    "            embeddings[section] = get_embedding(section_text)\n",
    "    return embeddings\n",
    "\n",
    "# Step 3: Create a retrieval system\n",
    "def find_most_relevant_section(query, embeddings):\n",
    "    query_embedding = get_embedding(query)\n",
    "    similarities = {}\n",
    "    for section, embedding in embeddings.items():\n",
    "        similarity = cosine_similarity([query_embedding], [embedding])[0][0]\n",
    "        similarities[section] = similarity\n",
    "    return max(similarities, key=similarities.get)\n",
    "\n",
    "# Step 4: Implement RAG\n",
    "def generate_response(query, structured_content, embeddings):\n",
    "    relevant_section = find_most_relevant_section(query, embeddings)\n",
    "    context = structured_content['GStreamerTutorial'][relevant_section]['content']\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant with expertise in GStreamer.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuery: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the structured content\n",
    "    with open(\"organized_data_from_GS.json\", \"r\") as file:\n",
    "        structured_content = json.load(file)\n",
    "    \n",
    "    # Create embeddings\n",
    "    embeddings = create_embeddings(structured_content)\n",
    "    \n",
    "    # Example usage of the RAG system\n",
    "    query = \"Explain the concept of dynamic pipelines in GStreamer.\"\n",
    "    response = generate_response(query, structured_content, embeddings)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    # print(f\"Embeddings: {embeddings}\")\n",
    "    \n",
    "    # Save the results to result.txt\n",
    "    with open(\"result.txt\", \"w\") as file:\n",
    "        file.write(f\"Query: {query}\\n\\n\")\n",
    "        file.write(f\"Response: {response}\\n\\n\")\n",
    "        file.write(\"Embeddings have been created for the following sections:\\n\")\n",
    "        for section in embeddings.keys():\n",
    "            file.write(f\"- {section}\\n\")\n",
    "    \n",
    "    # Save the embeddings for future use\n",
    "    with open(\"embeddings.json\", \"w\") as file:\n",
    "        json.dump({k: v for k, v in embeddings.items()}, file)\n",
    "    \n",
    "    print(\"Results have been saved to 'result.txt'\")\n",
    "    print(\"Embeddings have been saved to 'embeddings.json'\")\n",
    "\n",
    "# OUTPUT\n",
    "\n",
    "# Query: Explain the concept of dynamic pipelines in GStreamer.\n",
    "# Response: Dynamic pipelines in GStreamer refer to the ability to build and modify media processing pipelines 'on the fly'. This means that as new information becomes available or circumstances change, you can add, remove, or modify elements within your pipeline during runtime. This provides a great deal of flexibility and enables complex use-cases compared to static pipelines where all elements and their configurations are pre-defined when the pipeline is created.\n",
    "\n",
    "# One significant aspect of dynamic pipeline handling in GStreamer is \"Pad\" and \"Ghost Pad\". Pads act as input/output ports for elements and can be created or linked on demand. Ghost pad is a special type of pad to facilitate connection across bin boundaries, helping in encapsulating logic inside bins while dynamically linking elements.\n",
    "\n",
    "# Another important factor is understanding the different states of the elements and the pipelines. GStreamer pipelines have four different states - NULL, READY, PAUSED, and PLAYING. The transition between these states allows you to manage the system resources effectively and control the data flow between the elements. \n",
    "\n",
    "# However, working with dynamic pipelines requires correct handling of buffering, timestamps, event synchronization, and state changes. Understanding how to deal with these challenges is also crucial for successful implementation. \n",
    "\n",
    "# Monitoring or reacting to events is another vital part of GStreamer dynamic pipelines. Events like EOS (end-of-stream), errors, metadata updates, etc., can trigger actions in your application. You can listen to these events by connecting callback functions to the \"message\" signal emitted by the pipeline bus. \n",
    "\n",
    "# To conclude, dynamic pipelines offer a strong feature in GStreamer to build efficient, flexible, and complex multimedia applications. However, managing dynamic pipelines requires an understanding of various concepts like pad linking, states, event handling, etc.\n",
    "# Results have been saved to 'result.txt'\n",
    "# Embeddings have been saved to 'embeddings.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7d568-9c33-4d99-ba95-d245e9b8bd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25618ab4-1cac-493d-8c1c-1223326f3ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c9958-2ae2-41b8-a8d1-25360f82ff44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59465f2a-f35d-4b4f-aef3-ef4a42f126dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4778d4-681f-44ef-a96c-aab9a6301620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
